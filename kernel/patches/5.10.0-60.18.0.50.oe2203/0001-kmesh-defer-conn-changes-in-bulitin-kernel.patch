From d3bc659776b41804ffd7daec7f28877ac67400b6 Mon Sep 17 00:00:00 2001
From: Di Zhu <zhudi2@huawei.com>
Date: Tue, 11 Oct 2022 10:54:50 +0800
Subject: [PATCH] kmesh defer conn changes in bulitin kernel

Signed-off-by: Di Zhu <zhudi2@huawei.com>
---
 include/linux/bpf.h            |   7 +-
 include/net/inet_sock.h        |   3 +-
 include/net/protocol.h         |   2 +
 include/uapi/linux/bpf.h       |  35 +++++++
 kernel/bpf/cgroup.c            |   6 +-
 kernel/bpf/helpers.c           | 186 +++++++++++++++++++++++++++++++++
 kernel/bpf/verifier.c          |   3 +
 net/core/filter.c              |  72 +++++++++----
 net/ipv4/af_inet.c             |   2 +
 net/ipv4/tcp.c                 |   3 +-
 tools/include/uapi/linux/bpf.h |  36 +++++++
 11 files changed, 333 insertions(+), 22 deletions(-)

diff --git a/include/linux/bpf.h b/include/linux/bpf.h
index 5443178ff..bf002569e 100644
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@ -1164,6 +1164,7 @@ struct bpf_cg_run_ctx {
 		struct bpf_run_ctx *old_run_ctx;	\
 		struct bpf_cg_run_ctx run_ctx;		\
 		u32 _ret = 1;				\
+		u32 func_ret;               \
 		migrate_disable();			\
 		rcu_read_lock();			\
 		_array = rcu_dereference(array);	\
@@ -1173,7 +1174,11 @@ struct bpf_cg_run_ctx {
 		old_run_ctx = bpf_set_run_ctx(&run_ctx.run_ctx);\
 		while ((_prog = READ_ONCE(_item->prog))) {	\
 			run_ctx.prog_item = _item;	\
-			_ret &= func(_prog, ctx);	\
+			func_ret = func(_prog, ctx); \
+		        if (func_ret > 1)           \
+				_ret = func_ret;        \
+		        else                        \
+				_ret &= func_ret;          \
 			_item++;			\
 		}					\
 		bpf_reset_run_ctx(old_run_ctx);		\
diff --git a/include/net/inet_sock.h b/include/net/inet_sock.h
index f29059a26..2c8b13c7b 100644
--- a/include/net/inet_sock.h
+++ b/include/net/inet_sock.h
@@ -227,10 +227,11 @@ struct inet_sock {
 				nodefrag:1;
 	__u8			bind_address_no_port:1,
 				recverr_rfc4884:1,
-				defer_connect:1; /* Indicates that fastopen_connect is set
+				defer_connect:1, /* Indicates that fastopen_connect is set
 						  * and cookie exists so we defer connect
 						  * until first data frame is written
 						  */
+				bpf_defer_connect:1; /* Use bpf to decide whether defer connect */
 	__u8			rcv_tos;
 	__u8			convert_csum;
 	int			uc_index;
diff --git a/include/net/protocol.h b/include/net/protocol.h
index 2b778e1d2..8b76ff699 100644
--- a/include/net/protocol.h
+++ b/include/net/protocol.h
@@ -93,6 +93,8 @@ struct inet_protosw {
 #define INET_PROTOSW_REUSE 0x01	     /* Are ports automatically reusable? */
 #define INET_PROTOSW_PERMANENT 0x02  /* Permanent protocols are unremovable. */
 #define INET_PROTOSW_ICSK      0x04  /* Is this an inet_connection_sock? */
+#define INET_PROTOSW_PERMANENT_OVERRIDE      0x08
+
 
 extern struct net_protocol __rcu *inet_protos[MAX_INET_PROTOS];
 extern const struct net_offload __rcu *inet_offloads[MAX_INET_PROTOS];
diff --git a/include/uapi/linux/bpf.h b/include/uapi/linux/bpf.h
index 00afbbc13..ca3b43d0c 100644
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@ -3742,6 +3742,26 @@ union bpf_attr {
  * 	Return
  * 		The helper returns **TC_ACT_REDIRECT** on success or
  * 		**TC_ACT_SHOT** on error.
+ *
+ * int bpf_parse_header_msg(struct bpf_mem_ptr *msg)
+ * 	Description
+ * 		Parses the input msg information into the corresponding key-value 
+ * 		format and saves the format in the kernel. The specific 
+ * 		implementation is implemented by user-defined .ko.
+ * 	Return
+ * 		User-defined structure, such as the protocol type.
+ *
+ * void *bpf_get_msg_header_element(char *name)
+ *	Description
+ *		Used with *bpf_parse_header_msg* to obtain the corresponding key
+ *		from the data structure parsed by *bpf_parse_header_msg*.
+ *	Return
+ *		Contains a pointer to the data and the length of the data.
+ * int bpf_strlen(char *buff)
+ *	Description
+ *		Obtains the length of a character string.
+ *	Return
+ *		Length of the string
  */
 #define __BPF_FUNC_MAPPER(FN)		\
 	FN(unspec),			\
@@ -3900,6 +3920,15 @@ union bpf_attr {
 	FN(per_cpu_ptr),		\
 	FN(this_cpu_ptr),		\
 	FN(redirect_peer),		\
+	FN(strchr),             \
+	FN(strstr),             \
+	FN(strcmp),             \
+	FN(mem_replace),        \
+	FN(strcpy),             \
+	FN(strnstr),             \
+	FN(parse_header_msg),		\
+	FN(get_msg_header_element),	\
+	FN(strlen),			\
 	/* */
 
 /* integer value in 'imm' field of BPF_CALL instruction selects which helper
@@ -4727,6 +4756,7 @@ enum {
 					 * by the kernel or the
 					 * earlier bpf-progs.
 					 */
+    BPF_SOCK_OPS_TCP_DEFER_CONNECT_CB, /* defer connect */
 };
 
 /* List of TCP states. There is a build check in net/ipv4/tcp.c to detect
@@ -5032,6 +5062,11 @@ struct btf_ptr {
 	__u32 flags;		/* BTF ptr flags; unused at present. */
 };
 
+struct bpf_mem_ptr {
+    void *ptr;
+    __u32 size;
+};
+
 /*
  * Flags to control bpf_snprintf_btf() behaviour.
  *     - BTF_F_COMPACT: no formatting around type information
diff --git a/kernel/bpf/cgroup.c b/kernel/bpf/cgroup.c
index 7e1e50514..983b0e1e4 100644
--- a/kernel/bpf/cgroup.c
+++ b/kernel/bpf/cgroup.c
@@ -1119,7 +1119,11 @@ int __cgroup_bpf_run_filter_sock_addr(struct sock *sk,
 	cgrp = sock_cgroup_ptr(&sk->sk_cgrp_data);
 	ret = BPF_PROG_RUN_ARRAY(cgrp->bpf.effective[atype], &ctx, BPF_PROG_RUN);
 
-	return ret == 1 ? 0 : -EPERM;
+    if (ret == 1)
+        return 0;
+    if (ret == 0)
+        return 1;
+    return ret;
 }
 EXPORT_SYMBOL(__cgroup_bpf_run_filter_sock_addr);
 
diff --git a/kernel/bpf/helpers.c b/kernel/bpf/helpers.c
index 4bb5921a7..53117ae77 100644
--- a/kernel/bpf/helpers.c
+++ b/kernel/bpf/helpers.c
@@ -653,6 +653,178 @@ const struct bpf_func_proto bpf_this_cpu_ptr_proto = {
 	.arg1_type	= ARG_PTR_TO_PERCPU_BTF_ID,
 };
 
+#if 1
+BPF_CALL_2(bpf_strchr, void *, s, int, c)
+{
+    return strchr(s, c);
+}
+
+const struct bpf_func_proto bpf_strchr_proto = {
+    .func       = bpf_strchr,
+    .gpl_only   = false,
+    .ret_type   = RET_PTR_TO_ALLOC_MEM_OR_NULL,
+    .arg1_type  = ARG_ANYTHING,
+    .arg2_type  = ARG_ANYTHING,
+};
+
+BPF_CALL_2(bpf_strstr, void *, s1, void *, s2)
+{
+    return strstr(s1, s2);
+}
+
+const struct bpf_func_proto bpf_strstr_proto = {
+    .func       = bpf_strstr,
+    .gpl_only   = false,
+    .ret_type   = RET_PTR_TO_ALLOC_MEM_OR_NULL,
+    .arg1_type  = ARG_ANYTHING,
+    .arg2_type  = ARG_ANYTHING,
+};
+
+BPF_CALL_3(bpf_strnstr, void *, s1, void *, s2, size_t, len)
+{
+    return strnstr(s1, s2, len);
+}
+
+const struct bpf_func_proto bpf_strnstr_proto = {
+    .func       = bpf_strnstr,
+    .gpl_only   = false,
+    .ret_type   = RET_PTR_TO_ALLOC_MEM_OR_NULL,
+    .arg1_type  = ARG_ANYTHING,
+    .arg2_type  = ARG_ANYTHING,
+    .arg3_type  = ARG_ANYTHING,
+};
+
+BPF_CALL_2(bpf_strcmp, void *, str1, void *, str2)
+{
+    return strcmp(str1, str2);
+}
+
+const struct bpf_func_proto bpf_strcmp_proto = {
+    .func       = bpf_strcmp,
+    .gpl_only   = false,
+    .ret_type   = RET_INTEGER,
+    .arg1_type  = ARG_ANYTHING,
+    .arg2_type  = ARG_ANYTHING,
+};
+
+#if 1
+static void __bpf_memmove(char *dst, char *src, u32 srcLen)
+{
+    u32 i;
+    for (i = 0; i < srcLen; i++) {
+        dst[i] = src[i];
+    }
+    return;
+}
+
+static inline int __bpf_mem_replace(struct bpf_mem_ptr *mem,
+                                    struct bpf_mem_ptr *old,
+                                    struct bpf_mem_ptr *new)
+{
+#define BPF_OFFSET(ptr, size)   ((void *)((char *)(ptr) + (size)))
+#define BPF_MEM_PTR_VALID(m)    (((m)->ptr) && ((m)->size))
+
+    u32 newSize;
+    u32 size;
+    void *start = NULL;
+    void *newMem = NULL;
+    if (!BPF_MEM_PTR_VALID(mem) || !BPF_MEM_PTR_VALID(old) || !BPF_MEM_PTR_VALID(new))
+        return -1;
+
+    newSize = mem->size - old->size + new->size;
+    if (newSize <= mem->size) {
+        memcpy(old->ptr, new->ptr, new->size);
+        __bpf_memmove(BPF_OFFSET(old->ptr, new->size),
+                      BPF_OFFSET(old->ptr, old->size),
+                      (mem->size - (old->ptr - mem->ptr) - old->size));
+        mem->size = newSize;
+        return 0;
+    }
+
+    newMem = (void *)kmalloc(newSize, GFP_KERNEL);
+    if (!newMem)
+        return -1;
+
+    start = newMem;
+    /* start -- old */
+    size = old->ptr - mem->ptr;
+    if (size)
+        memcpy(start, mem->ptr, size);
+    /* new -- new + newSize */
+    memcpy(BPF_OFFSET(start, size), new->ptr, new->size);
+    size += new->size;
+
+    /* old + oldSize -- end */
+    if ((old->ptr + old->size) < (mem->ptr + mem->size)) {
+        memcpy(BPF_OFFSET(start, size),
+               BPF_OFFSET(old->ptr, old->size),
+               (newSize - size));
+    }
+
+    kfree(mem->ptr);
+    mem->ptr = newMem;
+    mem->size = newSize;
+    return 0;
+}
+
+#endif
+BPF_CALL_3(bpf_mem_replace, struct bpf_mem_ptr *, mem, struct bpf_mem_ptr *, old, struct bpf_mem_ptr *, new)
+{
+    /* replace old to new for mem */
+    return __bpf_mem_replace(mem, old, new);
+}
+
+const struct bpf_func_proto bpf_mem_replace_proto = {
+    .func       = bpf_mem_replace,
+    .gpl_only   = true,
+    .ret_type   = RET_INTEGER,
+    .arg1_type  = ARG_ANYTHING,
+    .arg2_type  = ARG_ANYTHING,
+    .arg3_type  = ARG_ANYTHING,
+};
+
+static inline
+int __bpf_strcpy(char *dst, u32 dst_size, const char *src)
+{
+    u32 src_size;
+    if (!dst || !src)
+        return -1;
+
+    src_size = strlen(src) + 1;
+    if (src_size > dst_size)
+        return -1;
+
+    (void)strcpy(dst, src);
+    return 0;
+}
+
+BPF_CALL_3(bpf_strcpy, void *, dst, u32, dst_size, void *, src)
+{
+    return __bpf_strcpy(dst, dst_size, src);
+}
+
+const struct bpf_func_proto bpf_strcpy_proto = {
+    .func       = bpf_strcpy,
+    .gpl_only   = true,
+    .ret_type   = RET_INTEGER,
+    .arg1_type  = ARG_ANYTHING,
+    .arg2_type  = ARG_ANYTHING,
+    .arg3_type  = ARG_ANYTHING,
+};
+
+BPF_CALL_1(bpf_strlen, void *, src)
+{
+	return strlen(src);
+}
+
+const struct bpf_func_proto bpf_strlen_proto = {
+	.func		= bpf_strlen,
+	.gpl_only	= false,
+	.ret_type	= RET_INTEGER,
+	.arg1_type	= ARG_ANYTHING,
+};
+#endif
+
 const struct bpf_func_proto bpf_get_current_task_proto __weak;
 const struct bpf_func_proto bpf_probe_read_user_proto __weak;
 const struct bpf_func_proto bpf_probe_read_user_str_proto __weak;
@@ -697,6 +869,20 @@ bpf_base_func_proto(enum bpf_func_id func_id)
 		return &bpf_ringbuf_discard_proto;
 	case BPF_FUNC_ringbuf_query:
 		return &bpf_ringbuf_query_proto;
+    case BPF_FUNC_strchr:
+        return &bpf_strchr_proto;
+    case BPF_FUNC_strstr:
+        return &bpf_strstr_proto;
+    case BPF_FUNC_strnstr:
+	return &bpf_strnstr_proto;
+    case BPF_FUNC_strcmp:
+        return &bpf_strcmp_proto;
+    case BPF_FUNC_mem_replace:
+        return &bpf_mem_replace_proto;
+    case BPF_FUNC_strcpy:
+        return &bpf_strcpy_proto;
+	case BPF_FUNC_strlen:
+		return &bpf_strlen_proto;
 	default:
 		break;
 	}
diff --git a/kernel/bpf/verifier.c b/kernel/bpf/verifier.c
index ac38a3dac..937176d85 100644
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@ -8402,6 +8402,9 @@ static int check_return_code(struct bpf_verifier_env *env)
 		    env->prog->expected_attach_type == BPF_CGROUP_INET4_GETSOCKNAME ||
 		    env->prog->expected_attach_type == BPF_CGROUP_INET6_GETSOCKNAME)
 			range = tnum_range(1, 1);
+        if (env->prog->expected_attach_type == BPF_CGROUP_INET4_CONNECT ||
+            env->prog->expected_attach_type == BPF_CGROUP_INET6_CONNECT)
+            range = tnum_range(0, 2);
 		break;
 	case BPF_PROG_TYPE_CGROUP_SKB:
 		if (env->prog->expected_attach_type == BPF_CGROUP_INET_EGRESS) {
diff --git a/net/core/filter.c b/net/core/filter.c
index 51514e410..6138413f0 100644
--- a/net/core/filter.c
+++ b/net/core/filter.c
@@ -5021,6 +5021,42 @@ static const struct bpf_func_proto bpf_sock_addr_getsockopt_proto = {
 	.arg5_type	= ARG_CONST_SIZE,
 };
 
+typedef u32 (*bpf_parse_protocol_func)(struct bpf_mem_ptr* msg);
+bpf_parse_protocol_func parse_protocol = NULL;
+EXPORT_SYMBOL(parse_protocol);
+
+typedef struct bpf_mem_ptr* (*bpf_get_protocol_element_func)(char *key);
+bpf_get_protocol_element_func get_protocol_element_func = NULL;
+EXPORT_SYMBOL(get_protocol_element_func);
+
+BPF_CALL_1(bpf_parse_header_msg, struct bpf_mem_ptr *, msg)
+{
+	if (!parse_protocol)
+		return -ENOTSUPP;
+	return parse_protocol(msg);
+}
+
+static const struct bpf_func_proto bpf_parse_header_msg_proto = {
+	.func		= bpf_parse_header_msg,
+	.gpl_only       = true,
+	.ret_type       = RET_INTEGER,
+	.arg1_type      = ARG_ANYTHING,
+};
+
+BPF_CALL_1(bpf_get_msg_header_element, char *, key)
+{
+	if (!get_protocol_element_func)
+		return -ENOTSUPP;
+	return get_protocol_element_func(key);
+}
+
+static const struct bpf_func_proto bpf_get_msg_header_element_proto = {
+	.func           = bpf_get_msg_header_element,
+	.gpl_only       = true,
+	.ret_type       = RET_PTR_TO_ALLOC_MEM_OR_NULL,
+	.arg1_type      = ARG_ANYTHING,
+};
+
 BPF_CALL_5(bpf_sock_ops_setsockopt, struct bpf_sock_ops_kern *, bpf_sock,
 	   int, level, int, optname, char *, optval, int, optlen)
 {
@@ -7283,6 +7319,10 @@ sock_ops_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)
 		return &bpf_sock_ops_reserve_hdr_opt_proto;
 	case BPF_FUNC_tcp_sock:
 		return &bpf_tcp_sock_proto;
+	case BPF_FUNC_parse_header_msg:
+		return &bpf_parse_header_msg_proto;
+	case BPF_FUNC_get_msg_header_element:
+		return &bpf_get_msg_header_element_proto;
 #endif /* CONFIG_INET */
 	default:
 		return bpf_sk_base_func_proto(func_id);
@@ -8064,9 +8104,15 @@ static bool sock_ops_is_valid_access(int off, int size,
 		switch (off) {
 		case offsetof(struct bpf_sock_ops, reply):
 		case offsetof(struct bpf_sock_ops, sk_txhash):
+        case offsetof(struct bpf_sock_ops, remote_ip4):
+        case offsetof(struct bpf_sock_ops, remote_port):
 			if (size != size_default)
 				return false;
 			break;
+        case offsetof(struct bpf_sock_ops, remote_ip6):
+            if (size != (4 * size_default))
+                return false;
+            break;
 		default:
 			return false;
 		}
@@ -9233,14 +9279,10 @@ static u32 sock_ops_convert_ctx_access(enum bpf_access_type type,
 		break;
 
 	case offsetof(struct bpf_sock_ops, remote_ip4):
-		BUILD_BUG_ON(sizeof_field(struct sock_common, skc_daddr) != 4);
-
-		*insn++ = BPF_LDX_MEM(BPF_FIELD_SIZEOF(
-						struct bpf_sock_ops_kern, sk),
-				      si->dst_reg, si->src_reg,
-				      offsetof(struct bpf_sock_ops_kern, sk));
-		*insn++ = BPF_LDX_MEM(BPF_W, si->dst_reg, si->dst_reg,
-				      offsetof(struct sock_common, skc_daddr));
+        SOCK_ADDR_LOAD_OR_STORE_NESTED_FIELD(
+            struct bpf_sock_ops_kern,
+            struct sock_common,
+            sk, skc_daddr, temp);
 		break;
 
 	case offsetof(struct bpf_sock_ops, local_ip4):
@@ -9300,16 +9342,10 @@ static u32 sock_ops_convert_ctx_access(enum bpf_access_type type,
 
 	case offsetof(struct bpf_sock_ops, remote_port):
 		BUILD_BUG_ON(sizeof_field(struct sock_common, skc_dport) != 2);
-
-		*insn++ = BPF_LDX_MEM(BPF_FIELD_SIZEOF(
-						struct bpf_sock_ops_kern, sk),
-				      si->dst_reg, si->src_reg,
-				      offsetof(struct bpf_sock_ops_kern, sk));
-		*insn++ = BPF_LDX_MEM(BPF_H, si->dst_reg, si->dst_reg,
-				      offsetof(struct sock_common, skc_dport));
-#ifndef __BIG_ENDIAN_BITFIELD
-		*insn++ = BPF_ALU32_IMM(BPF_LSH, si->dst_reg, 16);
-#endif
+        SOCK_ADDR_LOAD_OR_STORE_NESTED_FIELD(
+            struct bpf_sock_ops_kern,
+            struct sock_common,
+            sk, skc_dport, temp);
 		break;
 
 	case offsetof(struct bpf_sock_ops, local_port):
diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 67a081b5f..f1ccb61c0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1173,6 +1173,8 @@ void inet_register_protosw(struct inet_protosw *p)
 		/* Check only the non-wild match. */
 		if ((INET_PROTOSW_PERMANENT & answer->flags) == 0)
 			break;
+		if (p->flags & INET_PROTOSW_PERMANENT_OVERRIDE)
+			break;
 		if (protocol == answer->protocol)
 			goto out_permanent;
 		last_perm = lh;
diff --git a/net/ipv4/tcp.c b/net/ipv4/tcp.c
index fcd792816..c8f36a6d8 100644
--- a/net/ipv4/tcp.c
+++ b/net/ipv4/tcp.c
@@ -590,7 +590,8 @@ __poll_t tcp_poll(struct file *file, struct socket *sock, poll_table *wait)
 
 		if (tp->urg_data & TCP_URG_VALID)
 			mask |= EPOLLPRI;
-	} else if (state == TCP_SYN_SENT && inet_sk(sk)->defer_connect) {
+	} else if (state == TCP_SYN_SENT &&
+	(inet_sk(sk)->defer_connect || inet_sk(sk)->bpf_defer_connect)) {
 		/* Active TCP fastopen socket with defer_connect
 		 * Return EPOLLOUT so application can call write()
 		 * in order for kernel to generate SYN+data
diff --git a/tools/include/uapi/linux/bpf.h b/tools/include/uapi/linux/bpf.h
index 00afbbc13..03b836c04 100644
--- a/tools/include/uapi/linux/bpf.h
+++ b/tools/include/uapi/linux/bpf.h
@@ -3742,6 +3742,33 @@ union bpf_attr {
  * 	Return
  * 		The helper returns **TC_ACT_REDIRECT** on success or
  * 		**TC_ACT_SHOT** on error.
+ *
+ * char * bpf_strstr(void *s1, void *s2)
+ * 	Description
+ * 		strstr returns a apointer to the first occurrence of s2 in s1.
+ *
+ * 	Return
+ * 		pointer to the s1 substring
+ *
+ * int bpf_parse_header_msg(struct bpf_mem_ptr *msg)
+ * 	Description
+ * 		Parses the input msg information into the corresponding key-value 
+ * 		format and saves the format in the kernel. The specific 
+ * 		implementation is implemented by user-defined .ko.
+ * 	Return
+ * 		User-defined structure, such as the protocol type.
+ *
+ * void *bpf_get_msg_header_element(char *name)
+ *	Description
+ *		Used with *bpf_parse_header_msg* to obtain the corresponding key
+ *		from the data structure parsed by *bpf_parse_header_msg*.
+ *	Return
+ *		Contains a pointer to the data and the length of the data.
+ * int bpf_strlen(char *buff)
+ *	Description
+ *		Obtains the length of a character string.
+ *	Return
+ *		Length of the string
  */
 #define __BPF_FUNC_MAPPER(FN)		\
 	FN(unspec),			\
@@ -3900,6 +3927,15 @@ union bpf_attr {
 	FN(per_cpu_ptr),		\
 	FN(this_cpu_ptr),		\
 	FN(redirect_peer),		\
+	FN(strchr),             \
+	FN(strstr),             \
+	FN(strcmp),             \
+	FN(mem_replace),        \
+	FN(strcpy),        \
+	FN(strnstr),             \
+	FN(parse_header_msg),		\
+	FN(get_msg_header_element),	\
+	FN(strlen),			\
 	/* */
 
 /* integer value in 'imm' field of BPF_CALL instruction selects which helper
-- 
2.33.0

